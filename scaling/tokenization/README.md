# Tokenization Toolkit

Scripts and configs for tokenizer training, vocabulary updates, and compatibility layers with upstream datasets will live here.

> TODO: Provide tokenizer training defaults (e.g., sentencepiece model size) and describe how to version tokenizer artifacts.
